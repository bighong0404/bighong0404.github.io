# RowKey设计

> rowkey设计原则
> - 散列性
> - 唯一
> - 长度原则 (70-100个字符)

`考虑数据集中性: 同一类业务查询的数据尽量在一个region`

**举例:** 

1． 生成随机数、 hash、散列值

```
比如： 
原本rowKey为1001的，SHA1后变成： dd01903921ea24941c26a48f2cec24e0bb0e8cc7
原本rowKey为3001的，SHA1后变成： 49042c54de64a1e9bf0b33e00245660ef92dc7bd
原本rowKey为5001的，SHA1后变成： 7b61dec07e02c188790670af43e717f0f46e8913

在做此操作之前，一般我们会选择从数据集中抽取样本，来决定什么样的rowKey来Hash后作为每个分区的临界值。
```

2． 字符串反转

```
20170524000001 转成 10000042507102
20170524000002 转成 20000042507102
```

这样也可以在一定程度上散列逐步 put 进来的数据。

3． 字符串拼接

```
20170524000001_a12e
20170524000001_93i7
```



# 预分区

- 根据rowkey预分区

- 一个节点服务器最多存放2-3个region



规划未来半年-1年数据量,  若未来数据量增长超预期, 考虑旧数据导入新规划的表. 



# Sqoop

>  mysql to hadoop数据迁移工具





# 二级索引



**HBase**单纯从解决大数据实时读写问题角度出发，重点关注于分布式存储的扩展性、容错性、读写性能等方面，为此也牺牲了很多传统关系型数据库的功能，比如事务，SQL表达与分析等。

实际上，这是NoSQL最初的含义，以解决大数据的实时存取为首要目标，**提供简单的Get，Put，Scan接口，解决用户的大数据量存储的需求**。因此，HBase完全是一个非常优秀的大数据实时存取引擎，解决了传统数据库的容量问题。



HBase并不支持二级索引，只有rowkey作为一级索引， 如果要对库里的非rowkey字段进行数据检索和查询， 往往要通过MapReduce/Spark等分布式计算框架进行，硬件资源消耗和时间延迟都会比较高。

为了HBase支持对各个字段进行模糊查询和多字段组合的查询, 需要在原生HBase基础上构建二级索引， 以满足现实中更复杂多样的业务需求。一般有以下三类方案：

- 基于HBase的Coprocessor的方案（典型代表**phoenix**）
- 基于搜索平台的索引方案（如solr、ES等）
- 云厂商自研的二级索引（阿里云目前有自研增强版二级索引）


