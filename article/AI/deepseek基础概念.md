# 1. deepseek模型参数:

| architecture     | qwen2.5 | **含义**：模型底层架构基于**Qwen2**.5（通义千问2代架构的改进版），属于Transformer类模型的变体，优化了注意力机制和并行计算效率。<br /> **特点**：  支持长上下文理解和多任务泛化能力； 通过稀疏注意力（Sparse Attention）降低计算复杂度。 **应用场景**：适合需要长文本连贯性（如论文分析、代码生成）的任务。 |
| ---------------- | ------- | ------------------------------------------------------------ |
| parameters       | 1.8B    | 1.8bilion 参数, 在深度学习模型中，**参数（Parameters）** 是模型通过训练数据学习到的可调整权重，用于表征输入特征与输出预测之间的数学映射关系 |
| context length   | 131072  | **含义**：模型支持的**最大上下文窗口长度**为131,072个token（约12.8万词）。 <br />**技术意义**： <br />    **长文本处理**：可一次性输入约160页英文文档（按每页800词计算）； <br />    **依赖关系建模**：能捕捉更长距离的语义关联（如小说情节、复杂代码库）。 <br />**实际影响**：  内存占用较高（需更高显存，如24GB以上显卡）； 适合需要超长对话或文档分析的场景。 |
| embedding length | 1536    | **含义**：模型的**词向量维度**为1536维，即每个token被编码为一个1536维的向量。 <br />**技术意义**：  <br />     **语义表达能力**：高维度向量能更精细区分语义（如“银行”在金融和地理场景的不同含义）； <br />     **计算成本**：维度越高，矩阵运算量越大（需更高算力）。 <br />**应用场景**：需高精度语义匹配的任务（如问答、翻译）。 |
| quantization     | Q4_K_M  | **含义**：模型权重采用**4-bit分组量化**（GGUF格式），`K_M`为量化策略名称。 <br />**量化细节**：  <br />    **Q4**：4位存储权重（原精度为16位或32位），体积缩小约75%； <br />    **K_M**：中等粒度分组（平衡精度与压缩率），适合大多数消费级显卡。 <br />**实际影响**：  <br />    **优点**：显存需求降低（如7B模型从13GB→3.5GB），推理速度提升； <br />    **缺点**：精度损失约5%-10%（复杂任务可能表现略差）。 <br />**适用设备**：普通显卡（如RTX 3060 12GB）或CPU推理。 |



# 2. Qwen2架构的三个核心技术：

## 技术1: 动态稀疏注意力机制

- **原始问题**：传统AI读长文章时，每个字都要和之前所有字反复比对（相当于看一页书要翻回前100页核对），耗电又费时。
- **Qwen2方案**：
  - 读到"北京冬奥会"时，自动关联"冰墩墩""谷爱凌"等关键词，忽略"的""了"等无关字
  - 像人类扫读报纸：重点看标题、数字、人名，跳过连接词
- **效果**：处理10万字文本，计算量减少60%，速度提升3倍



## 技术2: 分级记忆系统

- **原始问题**：传统AI的"记忆"是均匀分布的，导致重要信息容易被冲淡
- **Qwen2方案**：
  - **短期记忆区**：记住当前对话的关键信息（如你刚说"我要写一篇关于气候变化的论文"）
  - **长期记忆区**：存储常识库（如二氧化碳的化学式、巴黎协定内容）
  - **缓存区**：临时存放正在处理的数据（如你上传的参考文献段落）
- **效果**：处理复杂任务时，信息调用准确率提升40%



## 技术3: 任务感知路由网络

- **原始问题**：传统AI同时处理多个任务时容易"手忙脚乱"
- **Qwen2方案**：
  - 遇到"请翻译这段话并总结要点"的指令时：
    ① 自动激活翻译模块（调用双语词库）
    ② 并行启动摘要模块（提取关键词）
    ③ 最后用校对模块整合结果
  - 各模块间通过"任务优先级通道"协调资源
- **效果**：多任务处理速度提升50%，错误率降低35%



这种架构设计，相当于让AI既具备教授的学识，又有编辑的效率，还像程序员一样擅长多线程工作。


![[./img/1大模型的历史.png]]

![[2发展历史.png]]

![[3生成式模型与推理模型的区别.png]]

![[4deepseek最新的生成模型与推理模型对比.png]]

![[5常见推理模型.png]]

![[6版本模型差异.png]]

![[7部署成本要求.png]]

![[8优劣势.png]]

![[9提示词通用公式1.png]]

![[9提示词通用公式2.png]]

![[9提示词技巧.png]]

![[9ds官方提示词建议.png]]