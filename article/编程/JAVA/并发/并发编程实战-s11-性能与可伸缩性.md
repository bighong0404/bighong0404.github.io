> 本章介绍各种分析, 监测以及提升并发程序性能的技术
>
> ## 11.1 对性能的思考
* 提升性能意味着用更少的资源做更多的事情.
* 资源通常指CPU时钟周期, 内存, 网络带宽, I/O带宽,  数据库请求, 磁盘空间等等.
* 多个线程与单线程相比, 会引入一些额外的性能开销: 线程之间的协作(加锁, 触发信号, 内存同步等), 增加的上下文切换, 线程的创建和销毁, 以及线程的调度等
* 过度使用线程会使得引入的开销超过多线程带来的各方面性能提升.
* 通过并发来获得更好的性能, 需要做好两件事: **更有效利用现有的资源**, 以及**在出现新的资源时使程序能尽可能利用起来**.

#### 1) 性能与可伸缩性

> 可伸缩性指: 当增加计算机资源时(CPU, 内存, 存储容量, I/O带宽等), 程序的吞吐量或者处理能力能响应地增加. 
>
> * 衡量性能的指标:  服务时间, 延迟时间, 执行效率, 吞吐量, 可伸缩性, 容量等. 其中一些指标用于衡量**运行速度(多块)**, 一些指标用于衡量**处理能力(多少)**. 

#### 2) 评估各种性能权衡因素

> 避免不成熟的优化. 首先使程序正确, 然后再提高运行呢速度.
* 大多数性能决策中都包含有多个变量, 并且非常依赖运行环境. 

## 11.2 Amdahl 's Law (阿姆达定律)

> 阿姆达定律: 在增加计算机资源的情况下, 程序在理论上能够实现最高加速比, 这个值取决于程序中可并行组件与串行组件所占的比重. 

F: 串行部分占比, $ 0 \leq F \leq 1 $
N: CPU核心数
$$ 加速比公式: Speedup \leq {1 \over {F + {(1-F) \over N}}} $$

* 从公式能看出, 但cpu核心数趋近无限大时,  加速比趋近于$1 \over F$, 意味着即使串行所占比例很小, 也会极大限制增加计算机资源所能够提神的吞吐率.
* 因此, 要预测程序在多处理器系统中能实现多大的加速比, 还需要找出任务中的串行部分.
> 在所有并发程序中都包含一些串行部分. 多检查容器类, 同步锁或者数据结构类等.

## 11.3 线程引入的开销
#### 1) 上下文切换

* 当可运行线程数大于CPU数量, 操作系统会把正在运行的线程调度出来, 让其他线程使用CPU.这就导致一次**上下文切换**. 上下文切换过程中会把当前运行现成的执行上下文保存, 把新调度进来的线程的执行上下文设置为当前上下文.
* 当一个新线程被调度进来时, 它所需的数据可能不在当前处理器的本地缓存中, 因此上下文切换将导致一些缓存缺失, 因而线程在首次调度运行时会更缓慢, 这也是调度器会为每个可运行的线程**分配一个最小CPU执行时间**的原因: 将上下文切换的开销分摊到更多不会中断的执行是江山, 从而提升整体的吞吐量(以损失响应性为代价).
* 当线程发生阻塞(竞争锁或者I/O), JVM通常会将这个线程挂起, 并允许交换出去. 若线程频繁阻塞, 它将无法使用完整的调度时间片. 程序发生阻塞越多, 发生的上下文切换越多, 调度开销会越大, 吞吐量越低.
* 上下文切换的实际开销随平台不同而不同. 按照经验: **上下文切换的开销相当于5000~10000个始终周期, 也就是几微妙**.
> **UNIX系统的vmstat命令**和**Windows系统的perfom工具**能报告上下文切换次数以及在内核中执行时间所占比例等信息.
#### 2) 内存同步
内存同步操作的性能开销包含多个方面, **编译器**和**JVM**都能通过**优化**来帮忙减少开销.

* synchronized和volatile提供的可见性保证中可能会使用一些特殊执行, 即**内存栅栏(Memory Barrier)**. 内存栅栏可以刷新缓存使缓存无效, 刷新硬件的写缓存, 以及停止执行管道. 内存栅栏会**抑制一些编译器优化操作**(例如代码重排)来对性能带来间接的影响.
* 现代JVM能通过优化来去掉一些不会发生竞争的锁, 从而减少不必要的同步开销. 例如在线程封闭的代码中使用了同步锁, JVM就会把这个锁获取操作优化掉, 因为不会有另一个程序跟当前程序在这个锁上发上同步.
```java
synchronize(new Object()){
  //do something
}
```
* 一些JVM还会通过**逸出分析**来找出不会发布到堆的本地对象引用, 把封锁在栈中的变量都自动成为线程本地变量, 这个优化操作成为**锁消除优化(Lock Elision)**.
* 编译器也能执行**锁粒度粗化操作(Lock Coarsening)**, 将临近的同步代码块用同一个锁合并起来.
```java
/*
方法中变量stooges是Vector, Vector是同步的. 每次add()都会获取/释放一次锁, toString()也会获取/释放一次.
而JVM分析出stooges变量以及其内部状态是不会逸出的, 因此会去掉这4次锁获取操作.
编译器还能把这四次获锁操作合并.
*/
public String gettStooeNames(){
  List<String> stooges = new Vector<String>();
  stooges.add("Moe");
  stooges.add("Larry"); 
  stooges.add("Curly");
  return stooges .toString();
}
```

#### 3) 阻塞

* 当锁竞争时, 竞争失败的线程会阻塞, 而JVM在实现阻塞行为时, 可能会采用**自旋等待**(Spin-Waiting, 通过循环不断尝试获锁直到成功), 或者通过**操作系统挂起**被阻塞的线程.
* 这两种方式的效率高低, 取决于上下文切换开销以及成功获锁之前需要等待多少时间. 时间较短适合自旋等待方式, 否则适合操作系统来挂起. JVM将根据对历史等待时间的分析数据来选择, 但**大多数JVM都是将线程挂起**.



## 11.4 减少锁的竞争

